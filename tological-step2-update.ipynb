{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6b7c63a-8aad-49be-a785-ea9274dc1a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a sample Python script.\n",
    "\n",
    "# Press Shift+F10 to execute it or replace it with your code.\n",
    "# Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import random\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.lines import Line2D\n",
    "import shapely.geometry as geometry\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import matplotlib.tri as tri\n",
    "from collections import Counter\n",
    "#\n",
    "#import geopandas as gpd\n",
    "#from geovoronoi import voronoi_regions_from_coords\n",
    "#from foronoi import Voronoi, Polygon, Visualizer, VoronoiObserver\n",
    "import shapely\n",
    "import math\n",
    "import matplotlib.tri as tri\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a20f319a-0a4f-48f0-a599-84240274ba1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45118bdf-172a-47bf-8d8e-eff9b313e482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_feature(folder):\n",
    "    inner_path = os.path.join(outer_path, folder)\n",
    "    total_num_folder = len(folderlist)\n",
    "    print ('total have %d folders' % (total_num_folder))\n",
    "    filelist = os.listdir(inner_path)\n",
    "    path_result0 = r'/mnt/c/Users/huhui/projects/tiatoolbox/examples/TCGA-test'\n",
    "    #path0 = r'/mnt/c/Users/huhui/projects/tiatoolbox/examples'\n",
    "    #path_result0 = os.path.join(path0, \"dep_result\")\n",
    "    #path_result = os.path.join(path_result0, str(folder))\n",
    "    #print(path_result, end='\\n')\n",
    "    #if not os.path.exists(path_result):\n",
    "       # mkdir(path_result)\n",
    "    all_vertex = []\n",
    "    all_position = []\n",
    "    all_distance = []\n",
    "    all_class = []\n",
    "    color = []  \n",
    "    #vor变量\n",
    "    #all_vertexvor = []\n",
    "    all_positionvor = []\n",
    "    vor_class = []\n",
    "    vor_area = []\n",
    "    for it in range(len(filelist)):\n",
    "        #print(folder)\n",
    "        patch_number = len(filelist)\n",
    "        print(patch_number)\n",
    "        csvname = filelist[it]\n",
    "        src1 = os.path.join(os.path.abspath(inner_path), filelist[it])\n",
    "        print(it)\n",
    "        table = xlrd.open_workbook(src1)\n",
    "        #读取Tri数据并计算特征\n",
    "        sheet1 = table.sheet_by_index(0)\n",
    "        nrow = sheet1.nrows\n",
    "        #print(nrow)\n",
    "        ncols = sheet1.ncols\n",
    "        title = sheet1.row_values(1)\n",
    "        all_vertex0 = sheet1.col_values(1)\n",
    "        list0 = [10000*it]*(nrow-1)\n",
    "        #print(len(list0))\n",
    "        #\n",
    "            #读取vor数据并计算特征\n",
    "        sheet2 = table.sheet_by_index(1)\n",
    "        nrowvor = sheet2.nrows\n",
    "        #ncols = sheet1.ncols\n",
    "        title2 = sheet2.row_values(1)\n",
    "        all_vertex1 = sheet2.col_values(1)\n",
    "        all_positionb = all_vertex1[1:]\n",
    "        all_positionb = [eval(x) for x in all_positionb]\n",
    "        all_positionvor = all_positionb + all_positionvor \n",
    "        area0 = sheet2.col_values(2)\n",
    "        vor_areaa = area0[1:]\n",
    "        vor_area = vor_area + vor_areaa\n",
    "        class0 = sheet2.col_values(3)\n",
    "        vor_classa = class0[1:]\n",
    "        vor_class = vor_classa +vor_class\n",
    "        dict_vorclass = defaultdict(list)\n",
    "        \n",
    "        \n",
    "        all_vertexa = all_vertex0[1:]\n",
    "        #print(len(all_vertex))\n",
    "        all_vertexa = np.sum([all_vertexa, list0], axis=0).tolist()\n",
    "        all_vertex = all_vertex + all_vertexa\n",
    "        #print(all_vertex)\n",
    "        #all_vertex = all_vertex0[1:]+list0\n",
    "        #print(all_vertex)\n",
    "        position0 = sheet1.col_values(2)\n",
    "        all_positiona = position0[1:]\n",
    "        all_positiona = [eval(x) for x in all_positiona]\n",
    "        all_position = all_position + all_positiona \n",
    "        #s = eval(position[1])\n",
    "        #s = list(map(int, s))\n",
    "        all_distance0 = sheet1.col_values(3)\n",
    "        all_distancea = all_distance0[1:]\n",
    "        all_distance = all_distance + all_distancea\n",
    "        all_class0 = sheet1.col_values(4)\n",
    "        all_classa = all_class0[1:]\n",
    "        all_class = all_class + all_classa \n",
    "        #a = len(set(all_class))\n",
    "        color0 = sheet1.col_values(5)\n",
    "        colora = color0[1:]\n",
    "        color = color + colora\n",
    "        \n",
    "    tri_number = len(all_distance)\n",
    "    print(tri_number)\n",
    "    tri_distance = sum(all_distance)\n",
    "    tri_meandistance = np.mean(all_distance)\n",
    "    tri_mediandistance = np.median(all_distance)\n",
    "    tri_vardistance = np.var(all_distance)\n",
    "    tri_stddistance = np.std(all_distance)\n",
    "    dict_distance = defaultdict(list)\n",
    "    dict_class = defaultdict(list)\n",
    "    dict_color = defaultdict(list)\n",
    "    dict_vectorcolor = defaultdict(list)\n",
    "    for item, distancea in zip(color, all_distance):\n",
    "        dict_color[item].append(distancea)\n",
    "    for vertex, item in zip(all_vertex, color):\n",
    "        dict_vectorcolor[vertex].append(item)\n",
    "\n",
    "    for vertex, distancea in zip(all_vertex, all_distance):\n",
    "        dict_distance[vertex].append(distancea)\n",
    "    #for vertex, distance in zip(all_vertex, all_distance):\n",
    "    #    dict_distance[vertex].append(distance)\n",
    "    for vertex, classnum in zip(all_vertex, all_class):\n",
    "        dict_class[vertex].append(classnum)\n",
    "    for item in list(dict_vectorcolor.keys()):\n",
    "        edge_type = dict_color.get(item)\n",
    "    ver_distance = []\n",
    "    ver_mix = []\n",
    "    list2 = []\n",
    "    for item in list(dict_distance.keys()):\n",
    "        v_Dis = dict_distance.get(item)\n",
    "        v_numbrt = len(v_Dis)\n",
    "        vrmain_distance = np.mean(v_Dis)\n",
    "        ver_distance.append(vrmain_distance)\n",
    "        v_color = dict_vectorcolor.get(item)\n",
    "        v_all = len(set(v_color))\n",
    "        n1 = v_color.count(0)\n",
    "        n2 = v_color.count(50)\n",
    "        n3 = v_color.count(100)\n",
    "        v_diff = v_numbrt - n1 - n2 - n3 + 1\n",
    "        v_mix = v_all/(v_numbrt*v_numbrt)*v_diff\n",
    "        ver_mix.append(v_mix)\n",
    "        mix_mean = np.mean(ver_mix)\n",
    "    mix_median = np.median(ver_mix)\n",
    "    mix_var = np.var(ver_mix)\n",
    "    mix_std = np.std(ver_mix)\n",
    "    ditance_mean = np.mean(ver_distance)\n",
    "    ditance_median = np.median(ver_distance)\n",
    "    ditance_var = np.var(ver_distance)\n",
    "    ditance_std = np.std(ver_distance)\n",
    "    list2.append(str(folder))\n",
    "    list2.append(mix_mean)\n",
    "    list2.append(mix_median)\n",
    "    list2.append(mix_var)\n",
    "    list2.append(mix_std)\n",
    "    list2.append(ditance_mean)\n",
    "    list2.append(ditance_median)\n",
    "    list2.append(ditance_var)\n",
    "    list2.append(ditance_std)\n",
    "    dict_mix0 = defaultdict(list)\n",
    "    dict_mix = defaultdict(list)\n",
    "    dict_compass = defaultdict(list)\n",
    "    for class0, mix in zip(all_class, ver_mix):\n",
    "        dict_mix[class0].append(mix)\n",
    "    for class0, distance in zip(all_class, ver_distance):\n",
    "        dict_compass[class0].append(distance)\n",
    "    keys = sorted(dict_mix.keys(), reverse=True)\n",
    "    #output_list = [dict_mix[key] for key in keys]\n",
    "    #for class0, distance in zip(keys, output_list):\n",
    "        #dict_mix0[class0].append(distance)\n",
    "   # for i, item in enumerate(keys):\n",
    "    if 3 not in keys:\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "    if 3 in keys:\n",
    "            mixnumber = dict_mix.get(3)\n",
    "            mean_mix = np.mean(mixnumber)\n",
    "            distance = dict_compass.get(3)\n",
    "            list2.append(np.mean(mixnumber))\n",
    "            list2.append(np.median(mixnumber))\n",
    "            list2.append(np.var(mixnumber))\n",
    "            list2.append(np.std(mixnumber))\n",
    "            list2.append(np.mean(distance))\n",
    "            list2.append(np.median(distance))\n",
    "            list2.append(np.var(distance))\n",
    "            list2.append(np.std(distance))\n",
    "    if 2 not in keys:\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "    if 2 in keys:\n",
    "            mixnumber = dict_mix.get(2)\n",
    "            mean_mix = np.mean(mixnumber)\n",
    "            distance = dict_compass.get(2)\n",
    "            list2.append(np.mean(mixnumber))\n",
    "            list2.append(np.median(mixnumber))\n",
    "            list2.append(np.var(mixnumber))\n",
    "            list2.append(np.std(mixnumber))\n",
    "            list2.append(np.mean(distance))\n",
    "            list2.append(np.median(distance))\n",
    "            list2.append(np.var(distance))\n",
    "            list2.append(np.std(distance))\n",
    "    if 1 not in keys:\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "    if 1 in keys:\n",
    "            mixnumber = dict_mix.get(1)\n",
    "            mean_mix = np.mean(mixnumber)\n",
    "            distance = dict_compass.get(1)\n",
    "            list2.append(np.mean(mixnumber))\n",
    "            list2.append(np.median(mixnumber))\n",
    "            list2.append(np.var(mixnumber))\n",
    "            list2.append(np.std(mixnumber))\n",
    "            list2.append(np.mean(distance))\n",
    "            list2.append(np.median(distance))\n",
    "            list2.append(np.var(distance))\n",
    "            list2.append(np.std(distance))\n",
    "    list1 = ['mix_mean', 'mix_median', 'mix_var', 'mix_std', 'compass_mean', 'compass_median', 'compass_var', 'compass_std', 'ttmix_mean', 'ttmix_median', 'ttmix_var', 'ttmix_std', 'ttcompass_mean', 'ttcompass_median', 'ttcompass_var', 'ttcompass_std',\n",
    "             'ssmix_mean', 'ssmix_median', 'ssmix_var', 'ssmix_std', 'sscompass_mean', 'sscompass_median', 'sscompass_var', 'sscompass_std',\n",
    "             'llmix_mean', 'llmix_median', 'llmix_var', 'llmix_std', 'llcompass_mean', 'llcompass_median', 'llcompass_var', 'llcompass_std',\n",
    "             'tt_number', 'tt_frequency', 'tt_distance', 'tt_meandistance', 'tt_mediandistance', 'tt_vardistance',\n",
    "             'tt_stddistance', 'll_number', 'll_frequency', 'll_distance', 'll_meandistance', 'll_mediandistance',\n",
    "             'll_vardistance', 'll_stddistance',\n",
    "             'ss_number', 'ss_frequency', 'ss_distance', 'ss_meandistance', 'ss_mediandistance', 'ss_vardistance',\n",
    "             'ss_stddistance', 'ts_number', 'ts_frequency', 'ts_distance', 'ts_meandistance', 'ts_mediandistance',\n",
    "             'ts_vardistance', 'ts_stddistance',\n",
    "             'sl_number', 'sl_frequency', 'sl_distance', 'sl_meandistance', 'sl_mediandistance', 'sl_vardistance',\n",
    "             'sl_stddistance', 'tl_number', 'tl_frequency', 'tl_distance', 'tl_meandistance', 'tl_mediandistance',\n",
    "             'tl_vardistance', 'tl_stddistance',\n",
    "             'tri_number', 'tri_distance', 'tri_meandistance', 'tri_mediandistance', 'tri_vardistance', 'tri_stddistance']\n",
    "\n",
    "\n",
    "    tumor_tumor = dict_color.get(0)\n",
    "    tt_number = len(tumor_tumor)\n",
    "    tt_distance = sum(tumor_tumor)\n",
    "    tt_meandistance = tt_distance/tt_number\n",
    "    #0:t-t 150: t-s 100:s-s  255:t-l  50:l-l 200:s-l\n",
    "    #list1 = ['tt_number', 'tt_frequency', 'tt_distance', 'tt_meandistance', 'tt_mediandistance', 'tt_vardistance', 'tt_stddistance', 'ts_number', 'ts_frequency', 'ts_distance', 'ts_meandistance', 'ts_mediandistance', 'ts_vardistance', 'ts_stddistance',\n",
    "             #'ss_number', 'ss_frequency', 'ss_distance', 'ss_meandistance', 'ss_mediandistance', 'ss_vardistance', 'ss_stddistance', 'tl_number', 'tl_frequency', 'tl_distance', 'tl_meandistance', 'tl_mediandistance', 'tl_vardistance', 'tl_stddistance',\n",
    "             #'ll_number', 'll_frequency', 'll_distance', 'll_meandistance', 'll_mediandistance', 'll_vardistance', 'll_stddistance', 'sl_number', 'sl_frequency', 'sl_distance', 'sl_meandistance', 'sl_mediandistance', 'sl_vardistance', 'sl_stddistance',\n",
    "             #'tri_number', 'tri_distance', 'tri_meandistance', 'tri_mediandistance', 'tri_vardistance', 'tri_stddistance']\n",
    "    #dic1 = dict.fromkeys(list1)'tt_meandistance',\n",
    "    #list7 = ['tt_number', 'tt_frequency', 'tt_distance', 'tt_meandistance', 'tt_mediandistance', 'tt_vardistance', 'tt_stddistance', 'll_number', 'll_frequency', 'll_distance', 'll_meandistance', 'll_mediandistance', 'll_vardistance', 'll_stddistance',\n",
    "             #'ss_number', 'ss_frequency', 'ss_distance', 'ss_meandistance', 'ss_mediandistance', 'ss_vardistance', 'ss_stddistance', 'ts_number', 'ts_frequency', 'ts_distance', 'ts_meandistance', 'ts_mediandistance', 'ts_vardistance', 'ts_stddistance',\n",
    "             #'sl_number', 'sl_frequency', 'sl_distance', 'sl_meandistance', 'sl_mediandistance', 'sl_vardistance', 'sl_stddistance', 'tl_number', 'tl_frequency', 'tl_distance', 'tl_meandistance', 'tl_mediandistance', 'tl_vardistance', 'tl_stddistance']\n",
    "    colorall = [0, 50, 100, 150, 200, 255]\n",
    "    keys_color = sorted(dict_color.keys())\n",
    "    for item in colorall:\n",
    "        if item in keys_color:\n",
    "            edge_type = dict_color.get(item)\n",
    "            number = len(edge_type)\n",
    "            list2.append(number)\n",
    "            edge_frequency = number/tri_number\n",
    "            list2.append(edge_frequency)\n",
    "            distance = sum(edge_type)\n",
    "            list2.append(distance)\n",
    "            mean_distance = np.mean(edge_type)\n",
    "            list2.append(mean_distance)\n",
    "            median_distance = np.median(edge_type)\n",
    "            list2.append(median_distance)\n",
    "            var_distance = np.var(edge_type)\n",
    "            list2.append(var_distance)\n",
    "            std_distance = np.std(edge_type)\n",
    "            list2.append(std_distance)\n",
    "        if item not in keys_color:\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "            list2.append(0)\n",
    "    list2.append(tri_number)\n",
    "    list2.append(tri_distance)\n",
    "    list2.append(tri_meandistance)\n",
    "    list2.append(tri_mediandistance)\n",
    "    list2.append(tri_vardistance)\n",
    "    list2.append(tri_stddistance)\n",
    "    dict1 = dict(zip(list1,list2))\n",
    "    \n",
    "    #读取vor数据并计算特征\n",
    "    ##sheet2 = table.sheet_by_index(1)\n",
    "    #nrow = sheet2.nrows\n",
    "    #ncols = sheet2.ncols\n",
    "   ## title2 = sheet2.row_values(1)\n",
    "    ##all_vertex0 = sheet2.col_values(1)\n",
    "   ## all_positon = all_vertex0[1:]\n",
    "   ## all_positon = [eval(x) for x in all_positon]\n",
    "   ## area0 = sheet2.col_values(2)\n",
    "   ## vor_area = area0[1:]\n",
    "   ## class0 = sheet2.col_values(3)\n",
    "   ## vor_class = class0[1:]\n",
    "   ## dict_vorclass = defaultdict(list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    vor_number = len(vor_area)\n",
    "    mean_vor = np.mean(vor_area)\n",
    "    var_vor = np.var(vor_area)\n",
    "    std_vor = np.std(vor_area)\n",
    "    compass_vor = std_vor/mean_vor\n",
    "    for item, area in zip(vor_class, vor_area):\n",
    "        dict_vorclass[item].append(area)\n",
    "    list4 = []\n",
    "    list3 = ['tumor_number', 'tumor_density', 'tumor_area', 'tumor_mean', 'tumor_median', 'tumor_var', 'tumor_std', 'tumor_compass',\n",
    "             'stormal_number', 'stormal_density', 'stormal_area', 'stormal_mean', 'stormal_median', 'stormal_var', 'stormal_std', 'stormal_compass',\n",
    "             'lym_number', 'lym_density', 'lym_area',  'lym_mean', 'lym_median', 'lym_var', 'lym_std', 'lym_compass',\n",
    "             'vor_number', 'mean_vor', 'var_vor', 'std_vor', 'compass_vor']\n",
    "    #3肿瘤2基质1淋巴\n",
    "    classall = [3, 2, 1]\n",
    "    keys_vorclass = sorted(dict_vorclass.keys(), reverse=True)\n",
    "    for item in classall:\n",
    "        if item in keys_vorclass:\n",
    "            vor_type = dict_vorclass.get(item)\n",
    "            number = len(vor_type)\n",
    "            list4.append(number)\n",
    "            density_vor = number / vor_number\n",
    "            list4.append(density_vor)\n",
    "            area = sum(vor_type)\n",
    "            list4.append(area)\n",
    "            mean_area = np.mean(vor_type)\n",
    "            list4.append(mean_area)\n",
    "            median_area = np.median(vor_type)\n",
    "            list4.append(median_area)\n",
    "            var_area = np.var(vor_type)\n",
    "            list4.append(var_area)\n",
    "            std_area = np.std(vor_type)\n",
    "            list4.append(std_area)\n",
    "            compass = std_area / mean_area\n",
    "            list4.append(compass)\n",
    "        if item not in keys_vorclass:\n",
    "            list4.append(0)\n",
    "            list4.append(0)\n",
    "            list4.append(0)\n",
    "            list4.append(0)\n",
    "            list4.append(0)\n",
    "            list4.append(0)\n",
    "            list4.append(0)\n",
    "            list4.append(0)\n",
    "    \n",
    "    \n",
    "    list4.append(vor_number)\n",
    "    list4.append(mean_vor)\n",
    "    list4.append(var_vor)\n",
    "    list4.append(std_vor)\n",
    "    list4.append(compass_vor)\n",
    "    dict2 = dict(zip(list3, list4))\n",
    "    dictaa = dict(dict1, **dict2)\n",
    "    listnew = list2+list4\n",
    "    #saveDict = {\"用户1\": \"密码1\"，\"用户2\": \"密码2\"}\n",
    "    return listnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1abf2d-75f7-44d1-8cb6-e2d9427074fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/huhui/projects/tiatoolbox/examples\n",
      "total have 1 folders\n",
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "191244\n",
      "43.88344955444336\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #table = xlrd.open_workbook(r'432831A4_7_Info.xlsx')\n",
    "    start = time.time()\n",
    "    outer_path = '/mnt/c/Users/huhui/projects/tiatoolbox/examples/TCGAHCC-result'\n",
    "    # Root directory of the project\n",
    "    ROOT_DIR = os.getcwd()\n",
    "    print(ROOT_DIR)\n",
    "    it=1\n",
    "    folderlist = os.listdir(outer_path)\n",
    "    fileName = \"TCGA-test.csv\"\n",
    "    name_attribute = ['patientID', 'mix_mean', 'mix_median', 'mix_var', 'mix_std', 'compass_mean', 'compass_median', 'compass_var', 'compass_std', 'ttmix_mean', 'ttmix_median', 'ttmix_var', 'ttmix_std', 'ttcompass_mean', 'ttcompass_median', 'ttcompass_var', 'ttcompass_std',\n",
    "            'ssmix_mean', 'ssmix_median', 'ssmix_var', 'ssmix_std', 'sscompass_mean', 'sscompass_median', 'sscompass_var', 'sscompass_std',\n",
    "            'llmix_mean', 'llmix_median', 'llmix_var', 'llmix_std', 'llcompass_mean', 'llcompass_median', 'llcompass_var', 'llcompass_std','tt_number', 'tt_frequency', 'tt_distance', 'tt_meandistance', 'tt_mediandistance',\n",
    "                          'tt_vardistance',\n",
    "                          'tt_stddistance', 'ts_number', 'ts_frequency', 'ts_distance', 'ts_meandistance',\n",
    "                          'ts_mediandistance',\n",
    "                          'ts_vardistance', 'ts_stddistance',\n",
    "                          'ss_number', 'ss_frequency', 'ss_distance', 'ss_meandistance', 'ss_mediandistance',\n",
    "                          'ss_vardistance',\n",
    "                          'ss_stddistance', 'tl_number', 'tl_frequency', 'tl_distance', 'tl_meandistance',\n",
    "                          'tl_mediandistance',\n",
    "                          'tl_vardistance', 'tl_stddistance',\n",
    "                          'll_number', 'll_frequency', 'll_distance', 'll_meandistance', 'll_mediandistance',\n",
    "                          'll_vardistance',\n",
    "                          'll_stddistance', 'sl_number', 'sl_frequency', 'sl_distance', 'sl_meandistance',\n",
    "                          'sl_mediandistance',\n",
    "                          'sl_vardistance', 'sl_stddistance',\n",
    "                          'tri_number', 'tri_distance', 'tri_meandistance', 'tri_mediandistance', 'tri_vardistance',\n",
    "                          'tri_stddistance', 'tumor_number', 'tumor_density', 'tumor_area',  'tumor_mean',\n",
    "                          'tumor_median', 'tumor_var', 'tumor_std', 'tumor_compass',\n",
    "                          'stormal_number', 'stormal_density', 'stormal_area', 'stormal_mean',\n",
    "                          'stormal_median', 'stormal_var', 'stormal_std', 'stormal_compass',\n",
    "                          'lym_number', 'lym_density', 'lym_area', 'lym_mean', 'lym_median', 'lym_var',\n",
    "                          'lym_std', 'lym_compass',\n",
    "                          'vor_number', 'mean_vor', 'var_vor', 'std_vor', 'compass_vor']\n",
    "    #tt = [\"a\", \"b\"]\n",
    "    \n",
    "    \n",
    "    with open(fileName, \"w\", newline='') as csv_file:\n",
    "           writer = csv.writer(csv_file)\n",
    "           #for key, value in dictaa.items:\n",
    "           writer.writerow(name_attribute)\n",
    "    \n",
    "           for folder in folderlist:\n",
    "                results = compute_feature(folder)  \n",
    "                writer.writerow(results)\n",
    "        \n",
    "        ##保存文件\n",
    "        #s=dictaa.items\n",
    "        #with open(fileName, \"w\") as csv_file:\n",
    "            #writer = csv.writer(csv_file)\n",
    "            #for key, value in dictaa.items:\n",
    "            #writer.writerow(results)\n",
    "        #fileObject = open('/mnt/c/Users/huhui/projects/tiatoolbox/examples/feature_result/TCGA-2Y-A9GV-01Z-00-DX1.524FA6DD-7C84-425C-A2B5-17690DF50A28_1_Info.csv', 'a')\n",
    "\n",
    "        # dataini = pd.DataFrame(columns=('numberx', 'numbery'))\n",
    "        #writerCSV = pd.DataFrame(columns=name_attribute)\n",
    "        # data = {'NumberID': list_inner, 'voro_area': voro_area, 'type_area': type_area}\n",
    "        #dataini = writerCSV._append(pd.DataFrame(results, index=[0]))\n",
    "        #dataini.to_csv(fileObject)\n",
    "        #fileObject.close()\n",
    "\n",
    "\n",
    "    print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b985e-c919-42b8-954f-5856de6c1075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tiatoolbox-dev]",
   "language": "python",
   "name": "conda-env-tiatoolbox-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
